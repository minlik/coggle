{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xglA5a0PmjxG"
   },
   "source": [
    "**任务1：报名比赛，下载比赛数据集并完成读取**\n",
    "\n",
    "- **步骤1** ：登录&报名比赛：https://aistudio.baidu.com/aistudio/competition/detail/45/0/task-definition\n",
    "- **步骤2** ：下载比赛数据集\n",
    "- **步骤3** ：使用`Pandas`完成数据读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v9AnG5_Hmnbn"
   },
   "outputs": [],
   "source": [
    "# !wget https://dataset-bj.cdn.bcebos.com/qianyan/bq_corpus.zip\n",
    "# !wget https://dataset-bj.cdn.bcebos.com/qianyan/lcqmc.zip\n",
    "# !wget https://dataset-bj.cdn.bcebos.com/qianyan/paws-x-zh.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kszIhXL3NZr5"
   },
   "outputs": [],
   "source": [
    "DataSet_Path = {\n",
    "    'lcqmc':\n",
    "            {'train':'data/lcqmc/train.tsv',\n",
    "             'dev':'data/lcqmc/dev.tsv',\n",
    "             'test':'data/lcqmc/test.tsv'},\n",
    "    'paws':\n",
    "            {'train':'data/paws-x-zh/train.tsv',\n",
    "             'dev':'data/paws-x-zh/dev.tsv',\n",
    "             'test':'data/paws-x-zh/test.tsv'},\n",
    "    'corpus':\n",
    "            {'train':'data/bq_corpus/train.tsv',\n",
    "             'dev':'data/bq_corpus/dev.tsv',\n",
    "             'test':'data/bq_corpus/test.tsv'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gs2rNz0bSp_h"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/goto456/stopwords/master/cn_stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2G_0BZnBSuYl"
   },
   "outputs": [],
   "source": [
    "with open('data/cn_stopwords.txt', 'r') as f:\n",
    "    stopwords = []\n",
    "    for word in f.readlines():\n",
    "        stopwords.append(word.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EQ9VYte-OIkB"
   },
   "outputs": [],
   "source": [
    "Train_Data_Style = ['text1', 'text2', 'label']\n",
    "Dev_Data_Style = ['text1', 'text2', 'label']\n",
    "Test_Data_Style = ['text1', 'text2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbVYLwmyunhZ",
    "outputId": "e0f26e68-aad0-4c53-b60c-0ea1a285aa39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuan/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus_train_df = pd.read_csv(DataSet_Path['corpus']['train'], sep='\\t\\n', header=None)\n",
    "text1 = np.asarray([i.split('\\t')[0] for i in corpus_train_df[0]])\n",
    "text2 = np.asarray([i.split('\\t')[1] for i in corpus_train_df[0]])\n",
    "label = np.asarray([i.split('\\t')[2] for i in corpus_train_df[0]])\n",
    "corpus_train_df['text1'] = text1\n",
    "corpus_train_df['text2'] = text2\n",
    "corpus_train_df['label'] = label.astype(int)\n",
    "corpus_train_df.drop(corpus_train_df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "corpus_dev_df = pd.read_table(DataSet_Path['corpus']['dev'], header=None)\n",
    "corpus_dev_df.columns = Dev_Data_Style\n",
    "\n",
    "corpus_test_df = pd.read_table(DataSet_Path['corpus']['test'], header=None)\n",
    "corpus_test_df.columns = Test_Data_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_HKu4y33PbZk",
    "outputId": "b7196d0b-2b38-459f-b564-1f9f67b02ab0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>用微信都6年，微信没有微粒贷功能</td>\n",
       "      <td>4。号码来微粒贷</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>微信消费算吗</td>\n",
       "      <td>还有多少钱没还</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>交易密码忘记了找回密码绑定的手机卡也掉了</td>\n",
       "      <td>怎么最近安全老是要改密码呢好麻烦</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你好我昨天晚上申请的没有打电话给我今天之内一定会打吗？</td>\n",
       "      <td>什么时候可以到账</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“微粒贷开通\"</td>\n",
       "      <td>你好，我的微粒贷怎么没有开通呢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text1             text2  label\n",
       "0             用微信都6年，微信没有微粒贷功能          4。号码来微粒贷      0\n",
       "1                       微信消费算吗           还有多少钱没还      0\n",
       "2         交易密码忘记了找回密码绑定的手机卡也掉了  怎么最近安全老是要改密码呢好麻烦      0\n",
       "3  你好我昨天晚上申请的没有打电话给我今天之内一定会打吗？          什么时候可以到账      0\n",
       "4                      “微粒贷开通\"   你好，我的微粒贷怎么没有开通呢      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09YabUPbQXL1",
    "outputId": "45856b72-f0ea-4ca4-b87e-16ae9dd2cfcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text1   100000 non-null  object\n",
      " 1   text2   100000 non-null  object\n",
      " 2   label   100000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "corpus_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5VqsfKKQ0Q_",
    "outputId": "2d86ee46-7060-4b2a-fe93-ff59163c5c42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50000\n",
       "1    50000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "W4vyvnkFohhS",
    "outputId": "d0c2f22d-129e-44b1-8916-a71d1e473d86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>不要借了我是试试看能否操作的</td>\n",
       "      <td>借款审核期间能否取消借款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>亲怎样才能在钱包里有微粒货的图标呢</td>\n",
       "      <td>借不到</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>你好，我还款银行怎么更换</td>\n",
       "      <td>怎么更换绑定还款的卡</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>我的借贷额度，怎么减少了呢？</td>\n",
       "      <td>微粒贷额度怎么才能降低</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>什么时候可以知道借款成功</td>\n",
       "      <td>2.多笔借款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text1         text2  label\n",
       "0     不要借了我是试试看能否操作的  借款审核期间能否取消借款      0\n",
       "1  亲怎样才能在钱包里有微粒货的图标呢           借不到      0\n",
       "2       你好，我还款银行怎么更换    怎么更换绑定还款的卡      1\n",
       "3     我的借贷额度，怎么减少了呢？   微粒贷额度怎么才能降低      0\n",
       "4       什么时候可以知道借款成功        2.多笔借款      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAoa2HTgvLEB",
    "outputId": "94eedbf7-656d-482c-ade2-d664e44277cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text1   10000 non-null  object\n",
      " 1   text2   10000 non-null  object\n",
      " 2   label   10000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus_dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pir55CEQ4Pl",
    "outputId": "ad0f0c61-286d-435a-85b4-af3530dc70cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1    5000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dev_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "tEACOUA3QqjB",
    "outputId": "2a70e31c-6835-4a3d-9486-8e6ecbf4c636"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>为什么我无法看到额度</td>\n",
       "      <td>为什么开通了却没有额度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>为啥换不了</td>\n",
       "      <td>为两次还都提示失败呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>借了钱，但还没有通过，可以取消吗？</td>\n",
       "      <td>可否取消</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>为什么我申请额度输入密码就一直是那个页面</td>\n",
       "      <td>为什么要输入支付密码来验证</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>今天借明天还款可以？</td>\n",
       "      <td>今天借明天还要手续费吗</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text1          text2\n",
       "0            为什么我无法看到额度    为什么开通了却没有额度\n",
       "1                 为啥换不了     为两次还都提示失败呢\n",
       "2     借了钱，但还没有通过，可以取消吗？           可否取消\n",
       "3  为什么我申请额度输入密码就一直是那个页面  为什么要输入支付密码来验证\n",
       "4            今天借明天还款可以？    今天借明天还要手续费吗"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6XkYMHSQtwa",
    "outputId": "6e10c1f1-92bb-4c03-d247-e4ef707cdd0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text1   10000 non-null  object\n",
      " 1   text2   10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evdLZ4_JsZr8"
   },
   "source": [
    "**任务2：对句子对提取TFIDF以及统计特征，训练和预测**\n",
    "\n",
    "- 参考代码：https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb\n",
    "\n",
    "- **步骤1** ：对句子对（句子A和句子B统计）如下特征：\n",
    "\n",
    "  - 句子A包含的字符个数、句子B包含的字符个数\n",
    "  - 句子A与句子B的编辑距离\n",
    "  - 句子A与句子B共有单词的个数\n",
    "  - 句子A与句子B共有字符的个数\n",
    "  - 句子A与句子B共有单词的个数 / 句子A字符个数\n",
    "  - 句子A与句子B共有单词的个数 / 句子B字符个数\n",
    "\n",
    "- **步骤2** ：计算TFIDF，并对句子A和句子B进行特征转换\n",
    "\n",
    "- **步骤3** ：计算句子A与句子B的TFIDF向量的内积距离\n",
    "\n",
    "- **步骤4** ：将上述特征送入分类模型，训练并预测，将结果预测提交到比赛网站。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cM3CbMmgQp9l"
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def edit_distance(row):\n",
    "    s = row['text1']\n",
    "    t = row['text2']\n",
    "    m, n = len(s), len(t)\n",
    "    dist = [[0] * (n+1) for _ in range(m+1)]\n",
    "    for i in range(1, m+1):\n",
    "        dist[i][0] = i\n",
    "    for j in range(1, n+1):\n",
    "        dist[0][j] = j\n",
    "    for i in range(1, m+1):\n",
    "        for j in range(1, n+1):\n",
    "            if s[i-1] == t[j-1]:\n",
    "                dist[i][j] = dist[i-1][j-1]\n",
    "            else:\n",
    "                dist[i][j] = min(dist[i-1][j-1],\n",
    "                                 dist[i-1][j],\n",
    "                                 dist[i][j-1]) + 1\n",
    "    return dist[-1][-1]\n",
    "\n",
    "def common_word(row):\n",
    "    sset = set(row['cut_text1'].split(' '))\n",
    "    tset = set(row['cut_text2'].split(' '))\n",
    "    return len(sset & tset)\n",
    "\n",
    "def common_char(row):\n",
    "    sset = set(list(row['text1']))\n",
    "    tset = set(list(row['text2']))\n",
    "    return len(sset & tset)\n",
    "\n",
    "def cut_text(text):\n",
    "    remove_char_list = list('[·’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+')\n",
    "    return ' '.join([word for word in jieba.cut(text) if word not in remove_char_list and word not in stopwords])\n",
    "\n",
    "def feature_extraction(df):\n",
    "    # 句子A包含的字符个数\n",
    "    df['text1_len'] = df['text1'].apply(len)\n",
    "    # 句子B包含的字符个数\n",
    "    df['text2_len'] = df['text2'].apply(len)\n",
    "    # 句子A与句子B的编辑距离\n",
    "    df['edit_distance'] = df.apply(edit_distance, axis=1)\n",
    "    # 句子A与句子B共有单词的个数\n",
    "    df['cut_text1'] = df['text1'].apply(cut_text)\n",
    "    df['cut_text2'] = df['text2'].apply(cut_text)\n",
    "    df['common_word'] = df.apply(common_word, axis=1)\n",
    "    # 句子A与句子B共有字符的个数\n",
    "    df['common_char'] = df.apply(common_char, axis=1)\n",
    "    # 句子A与句子B共有单词的个数 / 句子A字符个数\n",
    "    df['common_1'] = df.apply(lambda row: row['common_word'] / len(row['text1']), axis=1 )\n",
    "    # 句子A与句子B共有单词的个数 / 句子B字符个数\n",
    "    df['common_2'] = df.apply(lambda row: row['common_word'] / len(row['text2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIxkCfuZXiMK",
    "outputId": "634c057b-a7f7-4b7f-fa31-9711c92e5272"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.481 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "feature_extraction(corpus_train_df)\n",
    "feature_extraction(corpus_dev_df)\n",
    "feature_extraction(corpus_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Vjx6c8Azsp7Y"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def tfidf_extraction(vec, df):\n",
    "    # 计算TFIDF，并对句子A和句子B进行特征转换\n",
    "    text1_tfidf = vec.transform(df['cut_text1'])\n",
    "    text2_tfidf = vec.transform(df['cut_text2'])\n",
    "    # 计算句子A与句子B的TFIDF向量的内积距离\n",
    "    df['tfidf_sim'] = [cosine(tfidf1.toarray(), tfidf2.toarray()) for tfidf1, tfidf2 in zip(text1_tfidf, text2_tfidf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGtf8pZpUHaG",
    "outputId": "660c97c7-c5f4-4cca-e1d9-79ee8afcc00d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuan/.local/lib/python3.8/site-packages/scipy/spatial/distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "corpus_vec = TfidfVectorizer()\n",
    "train_corpus = pd.concat([corpus_train_df['cut_text1'] + corpus_train_df['cut_text2']], axis=0)\n",
    "corpus_vec.fit(train_corpus)\n",
    "\n",
    "tfidf_extraction(corpus_vec, corpus_train_df)\n",
    "tfidf_extraction(corpus_vec, corpus_dev_df)\n",
    "tfidf_extraction(corpus_vec, corpus_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6-MIgI7kzVWy"
   },
   "outputs": [],
   "source": [
    "corpus_train_df.fillna(0, inplace=True)\n",
    "corpus_dev_df.fillna(0, inplace=True)\n",
    "corpus_test_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5rSw9GSV7aFh"
   },
   "outputs": [],
   "source": [
    "features = ['text1_len', 'text2_len', 'edit_distance', 'common_word', 'common_char', 'common_1','common_2', 'tfidf_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfydwdKn7-vy",
    "outputId": "e18cadeb-2307-415c-9da2-20a8d932737e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus train score: 0.68719\n",
      "corpus valid score: 0.7011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(corpus_train_df[features], corpus_train_df['label'])\n",
    "corpus_train_score = pipe.score(corpus_train_df[features], corpus_train_df['label'])\n",
    "corpus_val_score = pipe.score(corpus_dev_df[features], corpus_dev_df['label'])\n",
    "print('corpus train score:', corpus_train_score)\n",
    "print('corpus valid score:', corpus_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CxT6a3apzkHF"
   },
   "outputs": [],
   "source": [
    "corpus_pred = pipe.predict(corpus_test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ug_Qd53M3Y71"
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(corpus_pred, columns=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WhHQVy9m4cVh"
   },
   "outputs": [],
   "source": [
    "df_pred.to_csv('submit/bq_corpus.tsv', index_label='index', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJv65_9d64rJ",
    "outputId": "4c950d5c-9cc6-4c02-94a2-3cbc6816e62a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuan/.local/lib/python3.8/site-packages/scipy/spatial/distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "lcqmc_train_df = pd.read_table(DataSet_Path['lcqmc']['train'], header=None)\n",
    "lcqmc_train_df.columns = Train_Data_Style\n",
    "\n",
    "lcqmc_dev_df = pd.read_table(DataSet_Path['lcqmc']['dev'], header=None)\n",
    "lcqmc_dev_df.columns = Dev_Data_Style\n",
    "\n",
    "lcqmc_test_df = pd.read_table(DataSet_Path['lcqmc']['test'], header=None)\n",
    "lcqmc_test_df.columns = Test_Data_Style\n",
    "\n",
    "feature_extraction(lcqmc_train_df)\n",
    "feature_extraction(lcqmc_dev_df)\n",
    "feature_extraction(lcqmc_test_df)\n",
    "\n",
    "lcqmc_vec = TfidfVectorizer()\n",
    "train_lcqmc = pd.concat([lcqmc_train_df['cut_text1'] + lcqmc_train_df['cut_text2']], axis=0)\n",
    "lcqmc_vec.fit(train_lcqmc)\n",
    "\n",
    "tfidf_extraction(lcqmc_vec, lcqmc_train_df)\n",
    "tfidf_extraction(lcqmc_vec, lcqmc_dev_df)\n",
    "tfidf_extraction(lcqmc_vec, lcqmc_test_df)\n",
    "\n",
    "lcqmc_train_df.fillna(0, inplace=True)\n",
    "lcqmc_dev_df.fillna(0, inplace=True)\n",
    "lcqmc_test_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq5ZzmNe7vbB",
    "outputId": "8e2576ef-8be1-475a-e33c-bfe0552df265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcqmc train score: 0.822001457493948\n",
      "lcqmc valid score: 0.6146330379459214\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(lcqmc_train_df[features], lcqmc_train_df['label'])\n",
    "lcqmc_train_score = pipe.score(lcqmc_train_df[features], lcqmc_train_df['label'])\n",
    "lcqmc_val_score = pipe.score(lcqmc_dev_df[features], lcqmc_dev_df['label'])\n",
    "print('lcqmc train score:', lcqmc_train_score)\n",
    "print('lcqmc valid score:', lcqmc_val_score)\n",
    "\n",
    "lcqmc_pred = pipe.predict(lcqmc_test_df[features])\n",
    "df_pred = pd.DataFrame(lcqmc_pred, columns=['prediction'])\n",
    "df_pred.to_csv('submit/lcqmc.tsv', index_label='index', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9AumaXJ-Atb",
    "outputId": "78fb2198-9608-45f1-d616-5148a31caa60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuan/.local/lib/python3.8/site-packages/scipy/spatial/distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paws train score: 0.6846420112953179\n",
      "paws valid score: 0.6305\n"
     ]
    }
   ],
   "source": [
    "paws_train_df = pd.read_table(DataSet_Path['paws']['train'], header=None)\n",
    "paws_train_df.columns = Train_Data_Style\n",
    "paws_train_df['text1'] = paws_train_df['text1'].astype(str)\n",
    "paws_train_df['text2'] = paws_train_df['text2'].astype(str)\n",
    "\n",
    "paws_dev_df = pd.read_table(DataSet_Path['paws']['dev'], header=None)\n",
    "paws_dev_df.columns = Dev_Data_Style\n",
    "paws_dev_df['text1'] = paws_dev_df['text1'].astype(str)\n",
    "paws_dev_df['text2'] = paws_dev_df['text2'].astype(str)\n",
    "\n",
    "paws_test_df = pd.read_table(DataSet_Path['paws']['test'], header=None)\n",
    "paws_test_df.columns = Test_Data_Style\n",
    "paws_test_df['text1'] = paws_test_df['text1'].astype(str)\n",
    "paws_test_df['text2'] = paws_test_df['text2'].astype(str)\n",
    "\n",
    "feature_extraction(paws_train_df)\n",
    "feature_extraction(paws_dev_df)\n",
    "feature_extraction(paws_test_df)\n",
    "\n",
    "paws_vec = TfidfVectorizer()\n",
    "train_paws = pd.concat([paws_train_df['cut_text1'] + paws_train_df['cut_text2']], axis=0)\n",
    "paws_vec.fit(train_paws)\n",
    "\n",
    "tfidf_extraction(paws_vec, paws_train_df)\n",
    "tfidf_extraction(paws_vec, paws_dev_df)\n",
    "tfidf_extraction(paws_vec, paws_test_df)\n",
    "\n",
    "paws_train_df.fillna(0, inplace=True)\n",
    "paws_dev_df.fillna(0, inplace=True)\n",
    "paws_test_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(paws_train_df[features], paws_train_df['label'])\n",
    "paws_train_score = pipe.score(paws_train_df[features], paws_train_df['label'])\n",
    "paws_val_score = pipe.score(paws_dev_df[features], paws_dev_df['label'])\n",
    "print('paws train score:', paws_train_score)\n",
    "print('paws valid score:', paws_val_score)\n",
    "\n",
    "paws_pred = pipe.predict(paws_test_df[features])\n",
    "df_pred = pd.DataFrame(paws_pred, columns=['prediction'])\n",
    "df_pred.to_csv('submit/paws-x.tsv', index_label='index', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzK1h7DcIWxB"
   },
   "source": [
    "**任务3：加载中文词向量，自己训练中文词向量**\n",
    "\n",
    "- **步骤1** ：使用`jieba`对中文句子进行分词\n",
    "- **步骤2** ：使用[gensim中Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)训练分词后的句子，得到词向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hQPjQZoA_5ZQ"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "class MySentences:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for sentence in self.data:\n",
    "            yield str(sentence).split()\n",
    "\n",
    "train_data = pd.concat([corpus_train_df['cut_text1'],\n",
    "                        corpus_train_df['cut_text2'], \n",
    "                        lcqmc_train_df['cut_text1'],\n",
    "                        lcqmc_train_df['cut_text2'],\n",
    "                        paws_train_df['cut_text1'],\n",
    "                        paws_train_df['cut_text2']], \n",
    "                       axis=0)\n",
    "sentences = MySentences(train_data)\n",
    "model = Word2Vec(sentences, vector_size=100, workers=-1, epochs=5)\n",
    "\n",
    "model.save('w2v.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZBQr5BYWfZ3"
   },
   "source": [
    "**任务4：使用中文词向量完成mean/max/sif句子编码**\n",
    "\n",
    "- **步骤1** ：单词通过word2vec编码为100维向量，则句子编码为N∗100的矩阵，N为句子单词个数。\n",
    "\n",
    "- **步骤2** ：将N*100的矩阵进行`max-pooling`编码，转为100维度。\n",
    "\n",
    "- **步骤3** ：将N*100的矩阵进行`mean-pooling`编码，转为100维度。\n",
    "\n",
    "- **步骤4** ：将N*100的矩阵与单词的IDF进行矩阵相乘，即按照单词的词频进行加权，进行`tfidf-pooling`编码，转为100维度。\n",
    "\n",
    "- **步骤5：**学习SIF编码的原理，进行sif编码，转为100维度。\n",
    "  - https://github.com/PrincetonML/SIF/blob/master/src/SIF_embedding.py#L30\n",
    "  - https://openreview.net/pdf?id=SyK00v5xx\n",
    "\n",
    "- **步骤6（可选）** ：通过上述步骤2-步骤5的编码，计算相似句子的相似度 vs 不相似句子的相似度， **绘制得到分布图，哪一种编码最优？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AB99s-hYWe4L"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('w2v.model')\n",
    "\n",
    "def max_pooling(model, sentence):\n",
    "    embeddings = []\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            embeddings.append(model.wv[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros((100,))\n",
    "    else:\n",
    "        return np.max(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HACwlFiXB0wi"
   },
   "outputs": [],
   "source": [
    "corpus_train_df['max_pooling1'] = corpus_train_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "corpus_dev_df['max_pooling1'] = corpus_dev_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "corpus_test_df['max_pooling1'] = corpus_test_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "\n",
    "lcqmc_train_df['max_pooling1'] = lcqmc_train_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "lcqmc_dev_df['max_pooling1'] = lcqmc_dev_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "lcqmc_test_df['max_pooling1'] = lcqmc_test_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "\n",
    "paws_train_df['max_pooling1'] = paws_train_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "paws_dev_df['max_pooling1'] = paws_dev_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "paws_test_df['max_pooling1'] = paws_test_df['cut_text1'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "\n",
    "corpus_train_df['max_pooling2'] = corpus_train_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "corpus_dev_df['max_pooling2'] = corpus_dev_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "corpus_test_df['max_pooling2'] = corpus_test_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "\n",
    "lcqmc_train_df['max_pooling2'] = lcqmc_train_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "lcqmc_dev_df['max_pooling2'] = lcqmc_dev_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "lcqmc_test_df['max_pooling2'] = lcqmc_test_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "\n",
    "paws_train_df['max_pooling2'] = paws_train_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "paws_dev_df['max_pooling2'] = paws_dev_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))\n",
    "paws_test_df['max_pooling2'] = paws_test_df['cut_text2'].apply(lambda sentence: max_pooling(model, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "nYyyTg0KCJHF"
   },
   "outputs": [],
   "source": [
    "def mean_pooling(model, sentence):\n",
    "    embeddings = []\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            embeddings.append(model.wv[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros((100,))\n",
    "    else:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "\n",
    "corpus_train_df['mean_pooling1'] = corpus_train_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "corpus_dev_df['mean_pooling1'] = corpus_dev_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "corpus_test_df['mean_pooling1'] = corpus_test_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "\n",
    "lcqmc_train_df['mean_pooling1'] = lcqmc_train_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "lcqmc_dev_df['mean_pooling1'] = lcqmc_dev_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "lcqmc_test_df['mean_pooling1'] = lcqmc_test_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "\n",
    "paws_train_df['mean_pooling1'] = paws_train_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "paws_dev_df['mean_pooling1'] = paws_dev_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "paws_test_df['mean_pooling1'] = paws_test_df['cut_text1'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "\n",
    "corpus_train_df['mean_pooling2'] = corpus_train_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "corpus_dev_df['mean_pooling2'] = corpus_dev_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "corpus_test_df['mean_pooling2'] = corpus_test_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "\n",
    "lcqmc_train_df['mean_pooling2'] = lcqmc_train_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "lcqmc_dev_df['mean_pooling2'] = lcqmc_dev_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "lcqmc_test_df['mean_pooling2'] = lcqmc_test_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "\n",
    "paws_train_df['mean_pooling2'] = paws_train_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "paws_dev_df['mean_pooling2'] = paws_dev_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))\n",
    "paws_test_df['mean_pooling2'] = paws_test_df['cut_text2'].apply(lambda sentence: mean_pooling(model, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9Nk36aieDHOx"
   },
   "outputs": [],
   "source": [
    "def tfidf_pooling(model, sentence, vec, vocab):\n",
    "    tfidf = vec.transform([sentence])\n",
    "    embeddings = []\n",
    "    weights = []\n",
    "    for idx, weight in zip(tfidf.indices, tfidf.data):\n",
    "        if idx not in vocab:\n",
    "            continue\n",
    "        word = vocab[idx]\n",
    "        try:\n",
    "            embeddings.append(model.wv[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        weights.append(weight)\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros((100,))\n",
    "    return np.average(embeddings, weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rl5tyVD7--ke"
   },
   "outputs": [],
   "source": [
    "corpus_vocab = corpus_vec.get_feature_names()\n",
    "lcqmc_vocab = lcqmc_vec.get_feature_names()\n",
    "paws_vocab = paws_vec.get_feature_names()\n",
    "\n",
    "corpus_train_df['tfidf_pooling1'] = corpus_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, corpus_vec, corpus_vocab))\n",
    "corpus_train_df['tfidf_pooling1'] = corpus_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, corpus_vec, corpus_vocab))\n",
    "corpus_train_df['tfidf_pooling1'] = corpus_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, corpus_vec, corpus_vocab))\n",
    "\n",
    "lcqmc_train_df['tfidf_pooling1'] = lcqmc_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, lcqmc_vec, lcqmc_vocab))\n",
    "lcqmc_train_df['tfidf_pooling1'] = lcqmc_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, lcqmc_vec, lcqmc_vocab))\n",
    "lcqmc_train_df['tfidf_pooling1'] = lcqmc_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, lcqmc_vec, lcqmc_vocab))\n",
    "\n",
    "paws_train_df['tfidf_pooling1'] = paws_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, paws_vec, paws_vocab))\n",
    "paws_train_df['tfidf_pooling1'] = paws_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, paws_vec, paws_vocab))\n",
    "paws_train_df['tfidf_pooling1'] = paws_train_df['cut_text1'].apply(lambda sentence: tfidf_pooling(model, sentence, paws_vec, paws_vocab))\n",
    "\n",
    "corpus_train_df['tfidf_pooling2'] = corpus_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, corpus_vec, corpus_vocab))\n",
    "corpus_train_df['tfidf_pooling2'] = corpus_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, corpus_vec, corpus_vocab))\n",
    "corpus_train_df['tfidf_pooling2'] = corpus_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, corpus_vec, corpus_vocab))\n",
    "\n",
    "lcqmc_train_df['tfidf_pooling2'] = lcqmc_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, lcqmc_vec, lcqmc_vocab))\n",
    "lcqmc_train_df['tfidf_pooling2'] = lcqmc_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, lcqmc_vec, lcqmc_vocab))\n",
    "lcqmc_train_df['tfidf_pooling2'] = lcqmc_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, lcqmc_vec, lcqmc_vocab))\n",
    "\n",
    "paws_train_df['tfidf_pooling2'] = paws_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, paws_vec, paws_vocab))\n",
    "paws_train_df['tfidf_pooling2'] = paws_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, paws_vec, paws_vocab))\n",
    "paws_train_df['tfidf_pooling2'] = paws_train_df['cut_text2'].apply(lambda sentence: tfidf_pooling(model, sentence, paws_vec, paws_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0dJnlsU_C2M"
   },
   "outputs": [],
   "source": [
    "corpus_train_df.to_csv('data/bq_corpus/train_feature.tsv', sep='\\t', index=False)\n",
    "corpus_dev_df.to_csv('data/bq_corpus/dev_feature.tsv', sep='\\t', index=False)\n",
    "corpus_test_df.to_csv('data/bq_corpus/test_feature.tsv', sep='\\t', index=False)\n",
    "\n",
    "lcqmc_train_df.to_csv('data/lcqmc/train_feature.tsv', sep='\\t', index=False)\n",
    "lcqmc_dev_df.to_csv('data/lcqmc/dev_feature.tsv', sep='\\t', index=False)\n",
    "lcqmc_test_df.to_csv('data/lcqmc/test_feature.tsv', sep='\\t', index=False)\n",
    "\n",
    "paws_train_df.to_csv('data/paws-x-zh/train_feature.tsv', sep='\\t', index=False)\n",
    "paws_dev_df.to_csv('data/paws-x-zh/dev_feature.tsv', sep='\\t', index=False)\n",
    "paws_test_df.to_csv('data/paws-x-zh/test_feature.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**步骤6（可选）** ：通过上述步骤2-步骤5的编码，计算相似句子的相似度 vs 不相似句子的相似度， **绘制得到分布图，哪一种编码最优？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def converter(instr):\n",
    "    return np.fromstring(instr[1:-1],sep=' ')\n",
    "convert_cols = ['mean_pooling1', 'mean_pooling2', 'max_pooling1', 'max_pooling2','tfidf_pooling1', 'tfidf_pooling2']\n",
    "\n",
    "corpus_train_df = pd.read_csv('data/bq_corpus/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "corpus_dev_df = pd.read_csv('data/bq_corpus/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "corpus_test_df = pd.read_csv('data/bq_corpus/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def sim_calc(df):\n",
    "    df['wv_mean_sim'] = [(1-cosine(vec1, vec2))/2 for vec1, vec2 in zip(df['mean_pooling1'], df['mean_pooling2'])]\n",
    "    df['wv_max_sim'] = [(1-cosine(vec1, vec2))/2 for vec1, vec2 in zip(df['max_pooling1'], df['max_pooling2'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuan/.local/lib/python3.8/site-packages/scipy/spatial/distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "sim_calc(corpus_train_df)\n",
    "sim_calc(corpus_dev_df)\n",
    "sim_calc(corpus_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_1 = corpus_train_df[corpus_train_df['label'] == 1]['wv_mean_sim'].mean()\n",
    "mean_0 = corpus_train_df[corpus_train_df['label'] == 0]['wv_mean_sim'].mean()\n",
    "corpus_train_df[corpus_train_df['label'] == 1]['wv_mean_sim'].plot.hist(bins=20, alpha=0.5, label=f'1: {mean_1:.4f}')\n",
    "corpus_train_df[corpus_train_df['label'] == 0]['wv_mean_sim'].plot.hist(bins=20, alpha=0.5, label=f'0: {mean_0:.4f}')\n",
    "plt.title('mean pooling similarity')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mean_1 = corpus_train_df[corpus_train_df['label'] == 1]['wv_max_sim'].mean()\n",
    "mean_0 = corpus_train_df[corpus_train_df['label'] == 0]['wv_max_sim'].mean()\n",
    "corpus_train_df[corpus_train_df['label'] == 1]['wv_max_sim'].plot.hist(bins=20, alpha=0.5, label=f'1: {mean_1:.4f}')\n",
    "corpus_train_df[corpus_train_df['label'] == 0]['wv_max_sim'].plot.hist(bins=20, alpha=0.5, label=f'0: {mean_0:.4f}')\n",
    "plt.title('max pooling similarity')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAV9klEQVR4nO3df6zdd33f8ecrEColbJ57uQHblF4xJNyI1oRdJUXhD2g1a6lViKjbKJmWMWqSKkNQGrKx4ahiyTQCUpZkGgpW8RgMxa6SKVkMsmPGPwkmbm9igSFaJZhISeyUG8dkoQQK3Pf++H5Nb64/Nz5JfH7c6+dDOvL5fM7ne877fHV9X/fz/ZmqQpKkpc4adwGSpMlkQEiSmgwISVKTASFJajIgJElNLx93AafLq171qpqZmRl3GZK0ojz00ENPVtV067VVExAzMzPMzc2NuwxJWlGSPLrca25ikiQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNa2aM6nHaeYjX3zRy37341tOYyWSdPo4g5AkNRkQkqQmA0KS1DTUgEjyD5M8keRfJplKsj/J4STbF43Z1vcdSDLT9zXHSpJGZ9gziD8FjvbPrwfuAjYBW5JsSjINXAdcCNwA3Lzc2CHXKUlaYmgBkWQjcBHwv/quLcDuqloA7uzbm4G9VfUssA+4OEmWGStJGqFhziBuBj4ALPTttVV1vH/+OLAeWEc/w+jD4DgwtczYkyS5Kslckrn5+fnhfAtJOkMNJSCSvAv4dlU9vLh7yfMFTnaif5CxVNWOqpqtqtnp6eYd8yRJL9KwTpS7DNiY5GvAa4GfAE8nmaqqY8AGupnDEeCtAEnOAtbSzSKONcZKkkZoKDOIqrqiqt5SVW8F/oxuB/TdwGV9EGwF9gD3AZuTnANcAtxfVdW/tnSsJGmERnkexI3ApcA3gHur6nBVPQncBBwEPgpcu9zYEdYpSWIE12Kqqo8tam5uvL4T2Lmk76nWWEnS6HgmtSSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTUMJiCQzSe5NcijJniQbk1yd5Ht936Ek5/djtyU5nORAkpm+byrJ/r5/+zBqlCQ9v2HNIH4MfKiqLgD2AtcBa4DtVXVB/3gkyXT/2oV0962+uV/+euAuYBOwJcmmIdUpSVrGUAKiqp6oqm8nORt4A/AQXUD8YMnQzcDeqnoW2AdcnCTAFmB3VS0Ad/ZtSdIIDW0fRJK3AU8DG4Hb6QLi2iTfSnJbkpcB64CjAH0YHAemgLVVdbx/q8eB9ct8xlVJ5pLMzc/PD+urSNIZaWgBUVUP0IXCAeATwCeBfwG8HZgFLm8sFmCh/3dpX+szdlTVbFXNTk9Pn77iJUnDPYqpqn4K3ApcWlWP9o954B66mcURYANAkrOAtXSziGNJpvq32UA/y5Akjc6wjmLaluSNfXMr8NdJLk/nXOCdwBxwH7A5yTnAJcD9VVXAHuCyPjS29m1J0gi9fEjvexD4VJL1dPsh3gu8u+8/D9hVVXcDJLmp738GuKJf/kZgF3ANcEdVHR5SnZKkZQwlIPpf6L+9pPsRul/8S8fuBHYu6XuK7ggnSdKYeCa1JKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNw7rl6EySe5McSrInycYkU0n2JzmcZPuisdv6vgNJZvq+5lhJ0ugMawbxY+BDVXUBsBe4DrgeuAvYBGxJsinJdP/ahcANwM398ieNHVKdkqRlDCUgquqJqvp2krOBNwAPAVuA3VW1ANzZtzcDe6vqWWAfcHGSLDNWkjRCQ9sHkeRtwNPARuB2YG1VHe9ffhxYD6wDjgL0YXAcmFpmbOszrkoyl2Rufn5+WF9Fks5IQwuIqnoAWAMcAD4BZNHLARYai53oH2QsVbWjqmaranZ6evq01C1J6gz1KKaq+ilwK3ApcCzJVP/SBrqZw5H+OUnOAtbSzSJaYyVJIzSso5i2JXlj39wKfBfYA1zWB8HWvn0fsDnJOcAlwP1VVcuMlSSN0MuH9L4HgU8lWU+3H+I9wPeBXcA1wB1VdRggyU39+GeAK/rlb2yNlSSNzlACov+F/tuNlzY3xu4Edi7pe6o1VpI0Op5JLUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmoZ1otyKMvORL467BEmaOM4gJElNBoQkqcmAkCQ1GRCSpCYDQpLUNFBAJPlqkg/2l++WJJ0BBp1B/B7wY+DPknw5yb9O8uoh1iVJGrOBAqKqnqiqT1fV7wA30N3I5y+T3JHkV4daoSRpLAbdxDST5KNJ5oArgfdV1euATwF3L7PMK5N8LskjSQ4meX2Sq5N8L8mh/nF+P3ZbksNJDiSZ6fumkuzv+7efji8rSRrcoJuY7gSeBN5RVX9YVQcAqup+uvtKt7wJ+EJVnQ/8Od3MYw2wvaou6B+PJJkGrgMu7Mfc3C9/PXAXsAnYkmTTC/96kqQXa9CAeA/w2ap6BiDJeUkuAqiqf9taoKoerKp9ffPLwOvoAuIHS4ZuBvZW1bPAPuDiJAG2ALuraoEuoLYM+qUkSS/doAHxeWBqUftHwH9+AZ9zEXCILiCuTfKtJLcleRmwDjgK0IfB8f6z1lbV8X75x4GTjqBKclWSuSRz8/PzL6AcSdKpDHqxvpfT/xLv/S3dL/tTSnIu8Cd0M4Cf9d0/Au4BLm8tAiz0/y7te46q2gHsAJidna1B6pEkDWbQgLgXuDfJZ+l+UV8JfGXAZT8D3F5V31ncmeQeYCPwCPDWvu8sYC3dLOJYkqmqOgZs4LkBJUkaskEPc/33dPsBfh+4AtgL/PGplktyC/B0Vd2S5BVJLk/nXOCdwBzdTu7NSc4BLgHur6oC9gCX9aGxtW9LkkZk4PtBVNVngc8OOj7J1cAHgL9Icqjvvhs4CJwH7Kqqu/uxN/X9z9AFEMCNwC66cy7uqKrDg362JOmlGyggklxKdyjqq+n2BwSoqvrHyy1TVZ8GPt146WONsTuBnUv6nqI7wkmSNAaDziD+K92hrg8DPx1aNZKkiTFoQHwd+EpV/XyYxUiSJsegAfGXwF1J/vfizqr6L6e/JEnSJBg0IH5Ot3lp7RBrkSRNkIECoqr+Q5LzgNdW1cNDrkmSNAEGvZrr++kut7Grb782yeeHWZgkabwGvRbTNcDvAD8EqKrHgF8bVlGSpPEbNCB+BvwSUABJ3sALOMlOkrTyDPpL/lq6ay/9SpL7gDfz92c8S5JWoUF3Uu/v7yb3m3Szjgf7i+hJklapQS+18ev908f6f9cnWe/1kSRp9Rp0E9OtS9q/DuzHzUyStGoNuonptxa3k/wa3U2AJEmr1KBHMS11hO7eDZKkVWrQfRAP0x/iCrwCmKG/1ackaXUadB/EpUvax6rqb09zLZKkCTLoJqZa8vjlJL9y4tFaIMkrk3wuySNJDiZ5fZKpJPuTHE6yfdHYbX3fgSQzfV9zrCRpNAadQdwD/CPgB317Hd3tQX9IFxj/pLHMm4AvVNWVSa4FbgDmgbvoNk99Ncm9dPszrqM7+e7twM3Au4Hrl46tqq+/oG8nSXrRBp1B/A2wqareUlVvAWaBg327FQ5U1YNVta9vfhl4HbAF2F1VC8CdfXszsLeqngX2ARcnyTJjJUkjMmhAzAA/OtGoqsfp/uIf1EXAIWBtVR3v+x4H1tPNRo7277sAHAemlhn7HEmuSjKXZG5+fv4FlCNJOpVBA+J/Ag8k+VCS9yfZCzw0yIJJzqU7Z+JWIItfAhZai/T9pxxbVTuqaraqZqenpwf7JpKkgQwUEFX1UeBjdH/FvwH4HPCHA37GZ4Dbq+o7wLEkU33/BrqZw5H+OUnOortr3fFlxkqSRmTQGwYFOBd4tKr+GPhz4LwBlrsFeLqqbum79gCX9UGwtW/fB2xOcg7dyXf3V1UtM1aSNCKDbmLaCfwG8Ed9+5fpZhHLSnI18AFgU5JDSQ4BX6A7p+IbwL1VdbiqngRuAg4CH6W7tDjAjUvHDlirJOk0SPfH+ikGJY9U1flJHu6PYiLJoaq6YOgVDmh2drbm5uZe1LIzH/niaa5mNL77cQ/skvTSJHmoqmZbrw16HsT3k5wPVJKz6a7i+tTpKlCSNHkGDYh/RXfC2huBY8DXgSuHVZQkafwGDYjXV9U/7Q9ZxeswSdLqN+hO6v8IXTAYDpJ0Zhh0BvG5JF+i28z08xOdVXXvUKqSJI3doAExCzwBvHNRXwEGhCStUs8bEEl+o6q+UVXvHVVBkqTJcKp9EP9tcSPJp4ZYiyRpgpwqILKkfdGwCpEkTZZTBcSpT7OWJK1Kp9pJvSnJsf55gH/QtwNUVU0tv6gkaSV73oCoqkGPcpIkrTKDnignSTrDGBCSpCYDQpLUZEBIkpqGGhBJPpzkSJIP9u2rk3zvxB3m+ntMkGRbksNJDiSZ6fumkuzv+7cPs05J0smGPYPYCyy+XdsaYHtVXdA/HkkyDVwHXAjcANzcj70euAvYBGxJsmnItUqSFhlqQFTVN4HHFnWtAX6wZNhmYG9VPQvsAy5OEmALsLuqFoA7+7YkaURGvQ9iDXBtkm8luS3Jy4B1wFGAPgyOA1PA2qo63i/3OLB+6ZsluSrJXJK5+fn50XwDSTpDjPpEuE/2//4IuAe4vDEmwALPvQ7Uib7nqKoddPeoYHZ21suCSNJpNNIZRFU92j/m6QJiI3AE2ACQ5CxgLd0s4liSE5fy2EA/y5AkjcbIAiLJK5Jcns65dDcfmgPuAzYnOQe4BLi/qgrYA1zWh8bWvi1JGpGhbWJKsg74EvAautuUvgv4CnAQOA/YVVV392Nv6vufAa7o3+JGYBdwDXBHVR0eVq2SpJMNLSCq6ihwQeOlGxtjdwI7l/Q9RXeEkyRpDDyTWpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkpqEGRJIPJzmS5IN9eyrJ/iSHk2xfNG5b33cgyczzjZUkjcawZxB7gS8ual8P3AVsArYk2ZRkGrgOuBC4Abh5ubFDrlWStMhQA6Kqvgk8tqhrC7C7qhaAO/v2ZmBvVT0L7AMuTpJlxkqSRmTU+yDWVtXx/vnjwHpgHXAUoA+D48DUMmOfI8lVSeaSzM3Pzw+9eEk6k4w6ILLk+cIyYxYGGVtVO6pqtqpmp6enT2uhknSmG3VAHEsy1T/fQDdzONI/J8lZwFq6WURrrCRpREYdEHuAy/og2Nq37wM2JzkHuAS4v6pqmbGSpBF5+bDeOMk64EvAa4CfJ/ld4A+AXcA1wB1VdbgfexNwEHgGuKJ/ixtbYyVJozG0gKiqo8AFjZc2N8buBHYu6XuqNVaSNBqeSS1JajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUtPIAyLJ95Ic6h+3JZlKsj/J4STbF43b1vcdSDIz6jol6Uw3tDvKPY9nquoXd5pLcgtwF7AD+GqSe4EjwHXAm4G3AzcD7x51oZJ0JhvpDCLJ2cBPlnRvAXZX1QJwZ9/eDOytqmeBfcDFSTLKWiXpTDfqTUxrgHVJHkjytSRvBdZW1fH+9ceB9cA64ChAHxzHgamlb5bkqiRzSebm5+dH8w0k6Qwx6oA4BlwK/BZwG/B5YPHMIMBCY7lmf1XtqKrZqpqdnp4+/dVK0hlspAFRnQer6u+A3cCrgf+X5MTsYAPdzOFI/5wkZwFr6WYRkqQRGelO6iTvAP5vVT0KvAv4DvAV4LIktwNbgffRhcSfJjkHeAdwf1XVKGtdCWY+8sUXvex3P77lNFYiaTUa9VFM3wc+nWQD3c7qK4HHgF3ANcAdVXUYIMlNwEHgGeCKEde56r2UcAEDRjoTjDQgqupbwD9rvLS5MXYnsHPoRUmSmjyTWpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaxnFHOa0CXihQWv2cQUiSmgwISVKTASFJajIgJElN7qTWiuLOcWl0JnoGkWRbksNJDiSZGXc9knQmmdgZRJJp4DrgzcDbgZuBd4+xJJ0mL/V2p+P4XGcfOhNNbEDQ3YZ0b1U9m2Qf8Nkkqaoad2E684wr1OClhZOhqJdikgNiHXAUoKoWkhwHpoAnTwxIchVwVd/8YZK/arzPqxYvs0JY82isiJpz03OaI6t5yee+WCtiHS9xptX8q8u9MMkBsVSAhcUdVbUD2PG8CyVzVTU7zMJON2seDWsevpVWL1jzYpO8k/oIsAEgyVnAWuD4WCuSpDPIJAfEfcDmJOcAlwD3u/9BkkZnYjcxVdWTSW4CDgLPAFe8yLd63k1QE8qaR8Oah2+l1QvW/Avxj3JJUsskb2KSJI2RASFJalrVAbESL9WR5HtJDvWP28Zdz3KSfDjJkSQf7NtTSfb363v7uOtradR89ZL1ff64azwhySuTfC7JI0kOJnn9pK/jZWqe2HUMkGQmyb19bXuSbFwB67lV81DW86rdB9FfquMB/v5SHe+rqom/VEeSR6pqov4TtSR5E/BB4JtVdWuSW4D/Q7ez7KvAH1XV18dY4kkaNf8b4G+q6r+PubSTJPlNYE1V7UtyLfAWYJ4JXsfL1Px1JnQdAyR5DfDKqvp2kvcDF9AdFDPJ67lV818xhPW8mmcQv7hUB7APuDhJxlzT80pyNvCTcdcxiKr6JvDYoq4twO6qWgDu7NsTpVHzGuAH46nm+VXVg1W1r29+GXgdE76Ol6l5YtcxQFU90f+iPRt4A/AQk7+eWzUPZT2v5oB4zqU66E6ymxprRae2BliX5IEkX0vy1nEX9AKsraoTJzI+DqwfZzEDWgNcm+RbSW5L8rJxF7SMi4BDrKx1fKLmiV/HSd4GPA1sBG5nBaznRs1DWc8Tex7EEJx0qY4JdAy4FHgY+D3g83R/IawEWfJ80tc1wCf7f38E3ANcDvyP8ZVzsiTnAn9C91fsP1/8EhO6jpfU/LO+e2LXcVU9kGQN8O+AT7ACfpYbNQ/lZ3k1zyBW3KU6qvNgVf0dsBt4dT+NXAmOJTkxQ9tAP3ubZFX1aP+Yp/tPtXHcNTV8Bri9qr7DylnHv6h5haxjquqnwK10f6CtiPW8uOZhrefVHBAr7lIdSd6R5MSVFd8FfKf/IVgJ9gCX9WG8tW9PrCSvSHJ5OucC7wTmxl3XYv2O/6er6pa+a+LX8eKaV8g63pbkjX1zK/BdJnw9N2r+62Gt51W7iek0XqpjlL4PfDrJBrqd1VeOuZ6mJOuALwGvAX6e5HeBPwB2AdcAd1TV4TGWeJKlNdMF8Ffofj7OA3ZV1d1jK3CJJFcDHwD+Ismhvnsb8J+Y3HXcqvluJnQd9w4Cn0qynm6b/nvo/h9O7M8yJ9f8XrqbqZ329bxqD3OVJL00q3kTkyTpJTAgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpr+PyrRZe/ABubIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_dev_df['cut_text2'].apply(lambda x: len(str(x).split())).plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务5：搭建SiamCNN/LSTM模型，训练和预测**\n",
    "\n",
    "- **步骤1** ：将训练好的word2vec作为深度学习embeeding层的初始化参数。\n",
    "- **步骤2** ：搭建SiamCNN（Word2Vec句子编码 + 1D CNN +FC）的孪生网络结构，完成训练和预测，提交测试集预测结果。\n",
    "- **步骤3** ：搭建SiamLSTM（Word2Vec句子编码 + LSTM + FC）的孪生网络结构，完成训练和预测，提交测试集预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def converter(instr):\n",
    "    return np.fromstring(instr[1:-1],sep=' ')\n",
    "convert_cols = ['mean_pooling1', 'mean_pooling2', 'max_pooling1', 'max_pooling2','tfidf_pooling1', 'tfidf_pooling2']\n",
    "\n",
    "corpus_train_df = pd.read_csv('data/bq_corpus/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "corpus_dev_df = pd.read_csv('data/bq_corpus/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "corpus_test_df = pd.read_csv('data/bq_corpus/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "\n",
    "lcqmc_train_df = pd.read_csv('data/lcqmc/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "lcqmc_dev_df = pd.read_csv('data/lcqmc/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "lcqmc_test_df = pd.read_csv('data/lcqmc/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "\n",
    "paws_train_df = pd.read_csv('data/paws-x-zh/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "paws_dev_df = pd.read_csv('data/paws-x-zh/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "paws_test_df = pd.read_csv('data/paws-x-zh/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([corpus_train_df[['cut_text1', 'cut_text2', 'label']],\n",
    "                      lcqmc_train_df[['cut_text1', 'cut_text2', 'label']],\n",
    "                      paws_train_df[['cut_text1', 'cut_text2', 'label']]], axis=0)\n",
    "dev_df = pd.concat([corpus_dev_df[['cut_text1', 'cut_text2', 'label']],\n",
    "                      lcqmc_dev_df[['cut_text1', 'cut_text2', 'label']],\n",
    "                      paws_dev_df[['cut_text1', 'cut_text2', 'label']]], axis=0)\n",
    "del corpus_train_df\n",
    "del corpus_dev_df\n",
    "del lcqmc_train_df\n",
    "del lcqmc_dev_df\n",
    "del paws_train_df\n",
    "del paws_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = gensim.models.Word2Vec.load('w2v.model')\n",
    "weights = torch.FloatTensor(model.wv.vectors)\n",
    "config = {'embedding_size': 100,\n",
    "          'feature_size': 100,\n",
    "          'window_sizes': [2, 3, 4],\n",
    "          'num_layers': 2,\n",
    "          'hidden_size': 64,\n",
    "          'max_len': 25}\n",
    "\n",
    "unk_idx = len(model.wv.key_to_index)\n",
    "pad_idx = unk_idx + 1\n",
    "\n",
    "model.wv.key_to_index['<UNK>'] = unk_idx\n",
    "model.wv.key_to_index['<PAD>'] = pad_idx\n",
    "\n",
    "model.wv.index_to_key.extend(['<UNK>', '<PAD>'])\n",
    "\n",
    "weights = torch.FloatTensor(np.concatenate((model.wv.vectors, np.zeros((2, 100))), axis=0))\n",
    "\n",
    "config['vocab_size'] = len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, model, df, train=True):\n",
    "        self.model = model\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text1 = str(self.df.iloc[idx]['cut_text1']).split()\n",
    "        text2 = str(self.df.iloc[idx]['cut_text2']).split()\n",
    "        out1 = [self.model.wv.key_to_index.get(t1, unk_idx) for t1 in text1]\n",
    "        out2 = [self.model.wv.key_to_index.get(t2, unk_idx) for t2 in text2]\n",
    "        len1 = min(len(text1), max_len)\n",
    "        len2 = min(len(text2), max_len)\n",
    "        if len(out1) > max_len:\n",
    "            out1 = out1[:max_len]\n",
    "        else:\n",
    "            out1 += [pad_idx] * (max_len - len(out1))\n",
    "        if len(out2) > max_len:\n",
    "            out2 = out2[:max_len]\n",
    "        else:\n",
    "            out2 += [pad_idx] * (max_len - len(out2))\n",
    "            \n",
    "        if self.train:\n",
    "            return torch.tensor(out1), torch.tensor(out2), len1, len2, torch.tensor(self.df.iloc[idx]['label'])\n",
    "        \n",
    "        return torch.tensor(out1), torch.tensor(out2), len1, len2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(model, train_df)\n",
    "dev_ds = MyDataset(model, dev_df)\n",
    "\n",
    "corpus_test_ds = MyDataset(model, corpus_test_df, train=False)\n",
    "lcqmc_test_ds = MyDataset(model, lcqmc_test_df, train=False)\n",
    "paws_test_ds = MyDataset(model, paws_test_df, train=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "dev_dl = DataLoader(dev_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "corpus_test_dl = DataLoader(corpus_test_ds, batch_size=batch_size, shuffle=False)\n",
    "lcqmc_test_dl = DataLoader(lcqmc_test_ds, batch_size=batch_size, shuffle=False)\n",
    "paws_test_dl = DataLoader(paws_test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def printbar():\n",
    "    nowtime = datetime.now()\n",
    "    print('========' * 8 + nowtime.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SiamCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(config['vocab_size'], config['embedding_size'], padding_idx=pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv2d(1, config['feature_size'], (kernel_size, config['embedding_size'])),\n",
    "                          nn.LeakyReLU(inplace=True),\n",
    "                          nn.AdaptiveAvgPool2d(1))\n",
    "            for kernel_size in config['window_sizes']\n",
    "        ])\n",
    "    \n",
    "        self.fc = nn.Sequential(nn.Linear(config['feature_size'] * len(config['window_sizes']), 100),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(100, 16))\n",
    "        \n",
    "        self.clf = nn.Sequential(nn.Linear(64, 16), nn.ReLU(inplace=True), nn.Linear(16, 2))\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        embed = self.embedding(x) # [batch_size, seq_len, embedding_size]\n",
    "        embed.unsqueeze_(1)\n",
    "        conv_out = [conv(embed) for conv in self.convs]\n",
    "        out = torch.cat(conv_out, dim=1)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        return self.fc(out)\n",
    "    \n",
    "    def cross_layer(self, x1, x2):\n",
    "        f1 = torch.mul(x1, x2)\n",
    "        f2 = torch.abs(x1 - x2)\n",
    "        return torch.cat([x1, x2, f1, f2], axis=1)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_once(x1)\n",
    "        out2 = self.forward_once(x2)\n",
    "        cross_feature = self.cross_layer(out1, out2)\n",
    "        out = self.clf(cross_feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamcnn = SiamCNN(config)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(siamcnn.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(net, epochs, loss_fn, train_dl, valid_dl, optimizer, rnn=False):\n",
    "    net.train()\n",
    "    printbar()\n",
    "    print('Start Training...')\n",
    "    total_train_loss = []\n",
    "    total_valid_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_loss = 0\n",
    "        count = 0\n",
    "        for x1, x2, len1, len2, y in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            if rnn == True:\n",
    "                y_out = net(x1, x2, len1, len2)\n",
    "            else:\n",
    "                y_out = net(x1, x2)\n",
    "            loss = loss_fn(y_out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            y_pred = torch.max(y_out, 1)[1]\n",
    "            count += (y_pred.numpy() == y.numpy()).mean()\n",
    "        train_acc = count / len(train_dl)\n",
    "        train_loss = epoch_train_loss / len(train_dl)\n",
    "        valid_loss, valid_acc = evaluate(net, loss_fn, valid_dl, rnn)\n",
    "        printbar()\n",
    "        print(f'Epoch: {epoch+1}, train loss: {train_loss:.4f}, valid loss: {valid_loss:.4f}, train_acc: {train_acc:.4f}, valid_acc: {valid_acc:.4f}')\n",
    "        total_train_loss.append(train_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "    return total_train_loss, total_valid_loss\n",
    "\n",
    "def evaluate(net, loss_fn, valid_dl, rnn):\n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, len1, len2, y in valid_dl:\n",
    "            if rnn == True:\n",
    "                y_out = net(x1, x2, len1, len2)\n",
    "            else:\n",
    "                y_out = net(x1, x2)\n",
    "            loss = loss_fn(y_out, y)\n",
    "            valid_loss += loss.item()\n",
    "            y_pred = torch.max(y_out, 1)[1]\n",
    "            count += (y_pred.numpy() == y.numpy()).mean()\n",
    "    return valid_loss / len(valid_dl), count / len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def predict(net, test_dl, rnn=False):\n",
    "    y_pred = []\n",
    "    for x1, x2, len1, len2 in test_dl:\n",
    "        if rnn == True:\n",
    "            y_out = net(x1, x2, len1, len2)\n",
    "        else:\n",
    "            y_out = net(x1, x2)\n",
    "        y_pred.extend(torch.max(y_out, 1)[1].tolist())\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================17:37:51\n",
      "Start Training...\n",
      "================================================================17:47:08\n",
      "Epoch: 1, train loss: 0.5808, valid loss: 0.6600, train_acc: 0.6927, valid_acc: 0.6529\n",
      "================================================================17:55:48\n",
      "Epoch: 2, train loss: 0.4588, valid loss: 0.5962, train_acc: 0.7784, valid_acc: 0.6947\n",
      "================================================================18:04:24\n",
      "Epoch: 3, train loss: 0.3901, valid loss: 0.6039, train_acc: 0.8211, valid_acc: 0.7098\n",
      "================================================================18:12:59\n",
      "Epoch: 4, train loss: 0.3358, valid loss: 0.6026, train_acc: 0.8521, valid_acc: 0.7284\n",
      "================================================================18:21:34\n",
      "Epoch: 5, train loss: 0.2883, valid loss: 0.6404, train_acc: 0.8774, valid_acc: 0.7249\n",
      "================================================================18:30:09\n",
      "Epoch: 6, train loss: 0.2483, valid loss: 0.6595, train_acc: 0.8973, valid_acc: 0.7252\n",
      "================================================================18:38:44\n",
      "Epoch: 7, train loss: 0.2156, valid loss: 0.7082, train_acc: 0.9129, valid_acc: 0.7245\n",
      "================================================================18:47:20\n",
      "Epoch: 8, train loss: 0.1898, valid loss: 0.7412, train_acc: 0.9246, valid_acc: 0.7263\n",
      "================================================================18:55:56\n",
      "Epoch: 9, train loss: 0.1691, valid loss: 0.8207, train_acc: 0.9329, valid_acc: 0.7272\n",
      "================================================================19:04:32\n",
      "Epoch: 10, train loss: 0.1510, valid loss: 0.8996, train_acc: 0.9407, valid_acc: 0.7257\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_loss, valid_loss = train(siamcnn, epochs, loss_fn, train_dl, dev_dl, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamcnn.state_dict, 'siamcnn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pred_cnn = predict(siamcnn, corpus_test_dl)\n",
    "lcqmc_pred_cnn = predict(siamcnn, lcqmc_test_dl)\n",
    "paws_pred_cnn = predict(siamcnn, paws_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(corpus_pred_cnn, columns=['prediction']).to_csv('submit/siamcnn/bq_corpus.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(lcqmc_pred_cnn, columns=['prediction']).to_csv('submit/siamcnn/lcqmc.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(paws_pred_cnn, columns=['prediction']).to_csv('submit/siamcnn/paws-x.tsv', sep='\\t', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_loss(train_loss, valid_loss, title):\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(valid_loss, label='valid loss')\n",
    "    plt.plot(title=title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(train_loss, valid_loss, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamGRU(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SiamGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(config['vocab_size'], \n",
    "                                      config['embedding_size'], \n",
    "                                      padding_idx=pad_idx)\n",
    "        \n",
    "        self.gru = nn.GRU(config['embedding_size'], \n",
    "                          config['hidden_size'],\n",
    "                          num_layers=config['num_layers'], \n",
    "                          bidirectional=True,\n",
    "                          batch_first=True, \n",
    "                          dropout=0.5)\n",
    "    \n",
    "        self.clf = nn.Sequential(nn.Linear(8 * config['hidden_size'], config['hidden_size']),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(config['hidden_size'], 2))\n",
    "        \n",
    "    def cross_layer(self, x1, x2):\n",
    "        f1 = torch.mul(x1, x2)\n",
    "        f2 = torch.abs(x1 - x2)\n",
    "        return torch.cat([x1, x2, f1, f2], axis=1)\n",
    "    \n",
    "    def forward_once(self, x, text_len):\n",
    "        embed = self.embedding(x)\n",
    "        output, _ = self.gru(embed) # batch_size, seq_len, 2 * hidden_size\n",
    "        avg_out = torch.mean(output, 1)\n",
    "        return avg_out\n",
    "        \n",
    "    def forward(self, x1, x2, text_len1, text_len2):\n",
    "        out1 = self.forward_once(x1, text_len1)\n",
    "        out2 = self.forward_once(x2, text_len2)\n",
    "        cross_features = self.cross_layer(out1, out2)\n",
    "        out = self.clf(cross_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================19:04:42\n",
      "Start Training...\n",
      "================================================================19:17:39\n",
      "Epoch: 1, train loss: 0.4959, valid loss: 0.6117, train_acc: 0.7611, valid_acc: 0.7076\n",
      "================================================================19:30:34\n",
      "Epoch: 2, train loss: 0.3795, valid loss: 0.5438, train_acc: 0.8324, valid_acc: 0.7317\n",
      "================================================================19:43:29\n",
      "Epoch: 3, train loss: 0.3078, valid loss: 0.5728, train_acc: 0.8697, valid_acc: 0.7462\n",
      "================================================================19:57:10\n",
      "Epoch: 4, train loss: 0.2528, valid loss: 0.6055, train_acc: 0.8958, valid_acc: 0.7466\n",
      "================================================================20:11:38\n",
      "Epoch: 5, train loss: 0.2099, valid loss: 0.6458, train_acc: 0.9162, valid_acc: 0.7459\n",
      "================================================================20:26:08\n",
      "Epoch: 6, train loss: 0.1781, valid loss: 0.6741, train_acc: 0.9294, valid_acc: 0.7469\n",
      "================================================================20:40:13\n",
      "Epoch: 7, train loss: 0.1553, valid loss: 0.7306, train_acc: 0.9386, valid_acc: 0.7532\n",
      "================================================================20:53:09\n",
      "Epoch: 8, train loss: 0.1385, valid loss: 0.8012, train_acc: 0.9451, valid_acc: 0.7484\n",
      "================================================================21:06:02\n",
      "Epoch: 9, train loss: 0.1260, valid loss: 0.8637, train_acc: 0.9502, valid_acc: 0.7487\n",
      "================================================================21:20:00\n",
      "Epoch: 10, train loss: 0.1164, valid loss: 0.8967, train_acc: 0.9539, valid_acc: 0.7461\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "siamgru = SiamGRU(config)\n",
    "optimizer = torch.optim.Adam(siamgru.parameters(), lr=1e-3)\n",
    "\n",
    "train_loss, valid_loss = train(siamgru, epochs, loss_fn, train_dl, dev_dl, optimizer, rnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pred_gru = predict(siamgru, corpus_test_dl, rnn=True)\n",
    "lcqmc_pred_gru = predict(siamgru, lcqmc_test_dl, rnn=True)\n",
    "paws_pred_gru = predict(siamgru, paws_test_dl, rnn=True)\n",
    "\n",
    "pd.DataFrame(corpus_pred_gru, columns=['prediction']).to_csv('submit/siamgru/bq_corpus.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(lcqmc_pred_gru, columns=['prediction']).to_csv('submit/siamgru/lcqmc.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(paws_pred_gru, columns=['prediction']).to_csv('submit/siamgru/paws-x.tsv', sep='\\t', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamgru.state_dict, 'siamgru.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务6：搭建InferSent模型，训练和预测**\n",
    "\n",
    "- **步骤1** ：将训练好的word2vex作为深度学习embeeding层的初始化参数。\n",
    "- **步骤2** ：搭建InferSent模型，尝试不同的交叉方法。\n",
    "- **步骤3** ：训练InferSent模型，提交测试集预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferSent(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(InferSent, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(model.wv.key_to_index), config['embedding_size'], padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(config['embedding_size'],\n",
    "                          config['hidden_size'],\n",
    "                          num_layers=config['num_layers'],\n",
    "                          bidirectional=True,\n",
    "                          batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        self.fc = nn.Sequential(nn.Linear(config['hidden_size'] * 8, config['hidden_size']),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(config['hidden_size'], 2))\n",
    "    \n",
    "    def cross_layer(self, x1, x2):\n",
    "        f1 = torch.mul(x1, x2)\n",
    "        f2 = torch.abs(x1 - x2)\n",
    "        return torch.cat([x1, x2, f1, f2], axis=1)\n",
    "    \n",
    "    def forward_once(self, x, text_len):\n",
    "        embed = self.embedding(x) \n",
    "        output, _ = self.lstm(embed) \n",
    "        sent_embed = torch.sum(output, axis=1) \n",
    "        text_len = text_len.unsqueeze(1)\n",
    "        pooled = sent_embed / text_len.expand_as(sent_embed)\n",
    "        return pooled\n",
    "        \n",
    "    def forward(self, x1, x2, len1, len2):\n",
    "        out1 = self.forward_once(x1, len1)\n",
    "        out2 = self.forward_once(x2, len2)\n",
    "        cross_feature = self.cross_layer(out1, out2)\n",
    "        out = self.fc(cross_feature)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================21:21:49\n",
      "Start Training...\n",
      "================================================================21:35:56\n",
      "Epoch: 1, train loss: 0.5741, valid loss: 0.7593, train_acc: 0.7027, valid_acc: 0.6514\n",
      "================================================================21:50:37\n",
      "Epoch: 2, train loss: 0.4491, valid loss: 0.6188, train_acc: 0.7911, valid_acc: 0.6971\n",
      "================================================================22:04:55\n",
      "Epoch: 3, train loss: 0.4320, valid loss: 0.6170, train_acc: 0.8014, valid_acc: 0.6937\n",
      "================================================================22:20:12\n",
      "Epoch: 4, train loss: 0.4255, valid loss: 0.6073, train_acc: 0.8058, valid_acc: 0.6967\n",
      "================================================================22:37:17\n",
      "Epoch: 5, train loss: 0.4218, valid loss: 0.6022, train_acc: 0.8073, valid_acc: 0.6954\n",
      "================================================================22:55:52\n",
      "Epoch: 6, train loss: 0.4203, valid loss: 0.6321, train_acc: 0.8083, valid_acc: 0.6956\n",
      "================================================================23:15:28\n",
      "Epoch: 7, train loss: 0.4202, valid loss: 0.6145, train_acc: 0.8082, valid_acc: 0.6964\n",
      "================================================================23:36:26\n",
      "Epoch: 8, train loss: 0.4222, valid loss: 0.6312, train_acc: 0.8069, valid_acc: 0.6920\n",
      "================================================================23:57:26\n",
      "Epoch: 9, train loss: 0.4218, valid loss: 0.6188, train_acc: 0.8066, valid_acc: 0.6921\n",
      "================================================================00:20:13\n",
      "Epoch: 10, train loss: 0.4220, valid loss: 0.6127, train_acc: 0.8072, valid_acc: 0.6903\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "infersent = InferSent(config)\n",
    "optimizer = torch.optim.Adam(infersent.parameters(), lr=1e-2)\n",
    "\n",
    "train_loss, valid_loss = train(infersent, epochs, loss_fn, train_dl, dev_dl, optimizer, rnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(infersent.state_dict, 'infersent.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务7：搭建ESIM模型，训练和预测**\n",
    "\n",
    "- **步骤1** ：将训练好的word2vec作为深度学习embeeding层的初始化参数。\n",
    "- **步骤2** ：搭建ESIM模型，尝试不同的交叉方法。\n",
    "- **步骤3** ：训练ESIM模型，提交测试集预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class ESIM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ESIM, self).__init__()\n",
    "        self.embedding = nn.Embedding(config['vocab_size'], config['embedding_size'], padding_idx=pad_idx)\n",
    "        self.lstm1 = nn.LSTM(config['embedding_size'], config['hidden_size'],\n",
    "                             num_layers=config['num_layers'],\n",
    "                             bidirectional=True,\n",
    "                             batch_first=True,\n",
    "                             dropout=0.5)\n",
    "        self.lstm2 = nn.LSTM(8 * config['hidden_size'], config['hidden_size'],\n",
    "                             num_layers=config['num_layers'],\n",
    "                             bidirectional=True,\n",
    "                             batch_first=True,\n",
    "                             dropout=0.5)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(8 * config['hidden_size'], config['hidden_size']),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(config['hidden_size'], 2))\n",
    "    \n",
    "    def soft_align_attention(self, x1, x2, mask1, mask2):\n",
    "        attention = torch.matmul(x1, x2.transpose(1, 2))\n",
    "        mask1 = mask1.float().masked_fill_(mask1, float('-inf'))\n",
    "        mask2 = mask2.float().masked_fill_(mask2, float('-inf'))\n",
    "        \n",
    "        weight1 = F.softmax(attention + mask2.unsqueeze(1), dim=-1)\n",
    "        x1_align = torch.matmul(weight1, x2)\n",
    "        weight2 = F.softmax(attention.transpose(1, 2) + mask1.unsqueeze(1), dim=-1)\n",
    "        x2_align = torch.matmul(weight2, x1)\n",
    "\n",
    "        return x1_align, x2_align   \n",
    "    \n",
    "    def submul(self, x1, x2):\n",
    "        sub = x1 - x2\n",
    "        mul = x1 * x2\n",
    "        return torch.cat([sub, mul], axis=-1)\n",
    "    \n",
    "    def pool(self, x):\n",
    "        # x = [batch_size, seq_len, 2 * hidden_size]\n",
    "        avg_pooled = self.avg_pool(x.transpose(1, 2)).squeeze(-1)\n",
    "        max_pooled = self.max_pool(x.transpose(1, 2)).squeeze(-1)\n",
    "        return torch.cat([avg_pooled, max_pooled], axis=-1)\n",
    "    \n",
    "    def forward(self, x1, x2, text_len1, text_len2):\n",
    "        emb1 = self.embedding(x1)\n",
    "        emb2 = self.embedding(x2)\n",
    "        \n",
    "        packed_emb1 = pack_padded_sequence(emb1, text_len1, batch_first=True, enforce_sorted=False)\n",
    "        packed_emb2 = pack_padded_sequence(emb2, text_len2, batch_first=True, enforce_sorted=False)\n",
    "        o1, _ = self.lstm1(packed_emb1)\n",
    "        o2, _ = self.lstm1(packed_emb2)\n",
    "        o1, _ = pad_packed_sequence(o1, batch_first=True, total_length=config['max_len'])\n",
    "        o2, _ = pad_packed_sequence(o2, batch_first=True, total_length=config['max_len'])\n",
    "        \n",
    "        mask1 = x1.eq(pad_idx)\n",
    "        mask2 = x2.eq(pad_idx)\n",
    "        \n",
    "        x1_align, x2_align = self.soft_align_attention(o1, o2, mask1, mask2)\n",
    "        x1_combined = torch.cat([o1, x1_align, self.submul(o1, x1_align)], axis=-1)\n",
    "        x2_combined = torch.cat([o2, x2_align, self.submul(o2, x2_align)], axis=-1)\n",
    "        \n",
    "        packed_x1_combined = pack_padded_sequence(x1_combined, text_len1, batch_first=True, enforce_sorted=False)\n",
    "        packed_x2_combined = pack_padded_sequence(x2_combined, text_len2, batch_first=True, enforce_sorted=False)\n",
    "        x1_compose, _ = self.lstm2(packed_x1_combined)\n",
    "        x2_compose, _ = self.lstm2(packed_x2_combined)\n",
    "        x1_compose, _ = pad_packed_sequence(x1_compose, batch_first=True, total_length=config['max_len'])\n",
    "        x2_compose, _ = pad_packed_sequence(x2_compose, batch_first=True, total_length=config['max_len'])\n",
    "        \n",
    "        x1_pooled = self.pool(x1_compose)\n",
    "        x2_pooled = self.pool(x2_compose)\n",
    "        combined_feature = torch.cat([x1_pooled, x2_pooled], axis=-1)\n",
    "        sim = self.fc(combined_feature)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================00:20:13\n",
      "Start Training...\n",
      "================================================================00:36:32\n",
      "Epoch: 1, train loss: 0.5097, valid loss: 0.5923, train_acc: 0.7532, valid_acc: 0.7045\n",
      "================================================================00:52:41\n",
      "Epoch: 2, train loss: 0.3732, valid loss: 0.5523, train_acc: 0.8370, valid_acc: 0.7415\n",
      "================================================================01:08:50\n",
      "Epoch: 3, train loss: 0.2965, valid loss: 0.5565, train_acc: 0.8768, valid_acc: 0.7546\n",
      "================================================================01:24:57\n",
      "Epoch: 4, train loss: 0.2402, valid loss: 0.5867, train_acc: 0.9027, valid_acc: 0.7564\n",
      "================================================================01:41:05\n",
      "Epoch: 5, train loss: 0.1987, valid loss: 0.6185, train_acc: 0.9211, valid_acc: 0.7598\n",
      "================================================================01:57:17\n",
      "Epoch: 6, train loss: 0.1679, valid loss: 0.6859, train_acc: 0.9336, valid_acc: 0.7558\n",
      "================================================================02:13:25\n",
      "Epoch: 7, train loss: 0.1451, valid loss: 0.7136, train_acc: 0.9426, valid_acc: 0.7542\n",
      "================================================================02:29:34\n",
      "Epoch: 8, train loss: 0.1295, valid loss: 0.8198, train_acc: 0.9488, valid_acc: 0.7536\n",
      "================================================================02:45:44\n",
      "Epoch: 9, train loss: 0.1172, valid loss: 0.8384, train_acc: 0.9532, valid_acc: 0.7570\n",
      "================================================================03:01:50\n",
      "Epoch: 10, train loss: 0.1082, valid loss: 0.8271, train_acc: 0.9568, valid_acc: 0.7527\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "esim = ESIM(config)\n",
    "optimizer = torch.optim.Adam(esim.parameters(), lr=1e-3)\n",
    "\n",
    "train_loss, valid_loss = train(esim, epochs, loss_fn, train_dl, dev_dl, optimizer, rnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pred_esim = predict(esim, corpus_test_dl, rnn=True)\n",
    "lcqmc_pred_esim = predict(esim, lcqmc_test_dl, rnn=True)\n",
    "paws_pred_esim = predict(esim, paws_test_dl, rnn=True)\n",
    "\n",
    "pd.DataFrame(corpus_pred_esim, columns=['prediction']).to_csv('submit/esim/bq_corpus.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(lcqmc_pred_esim, columns=['prediction']).to_csv('submit/esim/lcqmc.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(paws_pred_esim, columns=['prediction']).to_csv('submit/esim/paws-x.tsv', sep='\\t', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(esim.state_dict, 'esim.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务8：使用BERT或ERNIE完成NSP任务**\n",
    "\n",
    "- 参考代码：\n",
    "  - https://aistudio.baidu.com/aistudio/projectdetail/3168859\n",
    "  - [bert-nsp代码](https://gitee.com/coggle/competition-baseline/blob/master/competition/科大讯飞AI开发者大赛2021/中文问题相似度挑战赛/bert-nsp-xunfei.ipynb)\n",
    "- **步骤1** ：学习Bert模型的使用。\n",
    "- **步骤2** ：使用Bert完成NSP任务的训练和预测，提交测试集预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "DataSet_Path = {\n",
    "    'lcqmc':\n",
    "            {'train':'data/lcqmc/train.tsv',\n",
    "             'dev':'data/lcqmc/dev.tsv',\n",
    "             'test':'data/lcqmc/test.tsv'},\n",
    "    'paws':\n",
    "            {'train':'data/paws-x-zh/train.tsv',\n",
    "             'dev':'data/paws-x-zh/dev.tsv',\n",
    "             'test':'data/paws-x-zh/test.tsv'},\n",
    "    'corpus':\n",
    "            {'train':'data/bq_corpus/train.tsv',\n",
    "             'dev':'data/bq_corpus/dev.tsv',\n",
    "             'test':'data/bq_corpus/test.tsv'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(instr):\n",
    "    return np.fromstring(instr[1:-1],sep=' ')\n",
    "\n",
    "convert_cols = ['mean_pooling1', 'mean_pooling2', 'max_pooling1', 'max_pooling2','tfidf_pooling1', 'tfidf_pooling2']\n",
    "\n",
    "corpus_train_df = pd.read_csv('data/bq_corpus/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "corpus_dev_df = pd.read_csv('data/bq_corpus/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "corpus_test_df = pd.read_csv('data/bq_corpus/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "\n",
    "lcqmc_train_df = pd.read_csv('data/lcqmc/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "lcqmc_dev_df = pd.read_csv('data/lcqmc/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "lcqmc_test_df = pd.read_csv('data/lcqmc/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "\n",
    "paws_train_df = pd.read_csv('data/paws-x-zh/train_feature.tsv', sep='\\t', \n",
    "                              converters={col: converter for col in convert_cols})\n",
    "paws_dev_df = pd.read_csv('data/paws-x-zh/dev_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "paws_test_df = pd.read_csv('data/paws-x-zh/test_feature.tsv', sep='\\t',\n",
    "                              converters={col: converter for col in convert_cols})\n",
    "\n",
    "train_df = pd.concat([corpus_train_df[['text1', 'text2', 'label']],\n",
    "                      lcqmc_train_df[['text1', 'text2', 'label']],\n",
    "                      paws_train_df[['text1', 'text2', 'label']]], axis=0)\n",
    "dev_df = pd.concat([corpus_dev_df[['text1', 'text2', 'label']],\n",
    "                      lcqmc_dev_df[['text1', 'text2', 'label']],\n",
    "                      paws_dev_df[['text1', 'text2', 'label']]], axis=0)\n",
    "\n",
    "del corpus_train_df\n",
    "del corpus_dev_df\n",
    "del lcqmc_train_df\n",
    "del lcqmc_dev_df\n",
    "del paws_train_df\n",
    "del paws_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/kuan/bert/bert-base-chinese/'\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def printbar():\n",
    "    nowtime = datetime.now()\n",
    "    print('========' * 8 + nowtime.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[:1000]\n",
    "dev_df = dev_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(model_path + 'vocab.txt')\n",
    "train_encodings = tokenizer(list(train_df['text1'].apply(str)), list(train_df['text2'].apply(str)), truncation='longest_first', padding='max_length', max_length=50)\n",
    "dev_encodings = tokenizer(list(dev_df['text1']), list(dev_df['text2']), truncation='longest_first', padding='max_length', max_length=50)\n",
    "corpus_test_encodings = tokenizer(list(corpus_test_df['text1']), list(corpus_test_df['text2']), truncation='longest_first', padding='max_length', max_length=50)\n",
    "lcqmc_test_encodings = tokenizer(list(lcqmc_test_df['text1']), list(lcqmc_test_df['text2']), truncation='longest_first', padding='max_length', max_length=50)\n",
    "paws_test_encodings = tokenizer(list(paws_test_df['text1']), list(paws_test_df['text2']), truncation='longest_first', padding='max_length', max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['label'] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForNextSentencePrediction, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = BertDataset(train_encodings, list(train_df['label']))\n",
    "dev_ds = BertDataset(dev_encodings, list(dev_df['label']))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "dev_dl = DataLoader(dev_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test_ds = BertDataset(corpus_test_encodings)\n",
    "lcqmc_test_ds = BertDataset(lcqmc_test_encodings)\n",
    "paws_test_ds = BertDataset(paws_test_encodings)\n",
    "\n",
    "corpus_test_dl = DataLoader(corpus_test_ds, batch_size=batch_size, shuffle=False)\n",
    "lcqmc_test_dl = DataLoader(lcqmc_test_ds, batch_size=batch_size, shuffle=False)\n",
    "paws_test_dl = DataLoader(paws_test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/kuan/bert/bert-base-chinese/ were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model = BertForNextSentencePrediction.from_pretrained(model_path).to(device)\n",
    "\n",
    "optimizer = AdamW(bert_model.parameters(), lr=1e-5)\n",
    "len_dataset = len(train_ds)\n",
    "epochs = 10\n",
    "total_steps = (len_dataset // batch_size) * epochs\n",
    "warmup_ratio = 0.1\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_ratio * total_steps, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_train(bert, train_dl, valid_dl, epochs, optimizer, scheduler, device):\n",
    "    bert.train()\n",
    "    printbar()\n",
    "    print('Start Training...')\n",
    "    total_train_loss = []\n",
    "    total_valid_loss = []\n",
    "    iter_nums = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_loss = 0\n",
    "        count = 0\n",
    "        for batch in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            y_out = bert(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = y_out.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            y_pred = torch.max(y_out.logits, 1)[1]\n",
    "            count += (y_pred.cpu().numpy() == labels.cpu().numpy()).mean()\n",
    "        train_acc = count / len(train_dl)\n",
    "        train_loss = epoch_train_loss / len(train_dl)\n",
    "        valid_loss, valid_acc = evaluate(bert, valid_dl, device)\n",
    "        printbar()\n",
    "        print(f'Epoch: {epoch+1}, train loss: {train_loss:.4f}, valid loss: {valid_loss:.4f}, train_acc: {train_acc:.4f}, valid_acc: {valid_acc:.4f}')\n",
    "        total_train_loss.append(train_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        bert.save_pretrained(f'bert_epoch_{epoch}')\n",
    "    return total_train_loss, total_valid_loss\n",
    "\n",
    "def evaluate(bert, valid_dl, device):\n",
    "    bert.eval()\n",
    "    valid_loss = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dl:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            y_out = bert(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = y_out.loss\n",
    "            valid_loss += loss.item()\n",
    "            y_pred = torch.max(y_out.logits, 1)[1]\n",
    "            count += (y_pred.cpu().numpy() == labels.cpu().numpy()).mean()\n",
    "    return valid_loss / len(valid_dl), count / len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================11:43:33\n",
      "Start Training...\n",
      "================================================================11:45:31\n",
      "Epoch: 1, train loss: 0.8901, valid loss: 0.6457, train_acc: 0.5208, valid_acc: 0.6478\n",
      "================================================================11:47:35\n",
      "Epoch: 2, train loss: 0.5988, valid loss: 0.6087, train_acc: 0.6875, valid_acc: 0.6736\n",
      "================================================================11:50:15\n",
      "Epoch: 3, train loss: 0.4525, valid loss: 0.6044, train_acc: 0.8036, valid_acc: 0.6895\n",
      "================================================================11:53:06\n",
      "Epoch: 4, train loss: 0.2724, valid loss: 0.7187, train_acc: 0.9028, valid_acc: 0.6786\n",
      "================================================================11:55:21\n",
      "Epoch: 5, train loss: 0.1233, valid loss: 0.8532, train_acc: 0.9663, valid_acc: 0.6786\n",
      "================================================================11:57:44\n",
      "Epoch: 6, train loss: 0.0436, valid loss: 1.0406, train_acc: 0.9901, valid_acc: 0.7063\n",
      "================================================================12:00:29\n",
      "Epoch: 7, train loss: 0.0320, valid loss: 1.0659, train_acc: 0.9911, valid_acc: 0.7103\n",
      "================================================================12:02:35\n",
      "Epoch: 8, train loss: 0.0177, valid loss: 1.0950, train_acc: 0.9940, valid_acc: 0.7054\n",
      "================================================================12:04:35\n",
      "Epoch: 9, train loss: 0.0052, valid loss: 1.1523, train_acc: 1.0000, valid_acc: 0.7133\n",
      "================================================================12:06:38\n",
      "Epoch: 10, train loss: 0.0040, valid loss: 1.1476, train_acc: 1.0000, valid_acc: 0.7192\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = bert_train(bert_model, train_dl, dev_dl, epochs, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_predict(bert, test_dl):\n",
    "    bert.eval()\n",
    "    y_pred = []\n",
    "    for batch in test_dl:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        y_out = bert(input_ids, attention_mask=attention_mask)\n",
    "        y_pred.extend(torch.max(y_out.logits, 1)[1].tolist())\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pred_bert = bert_predict(bert_model, corpus_test_dl)\n",
    "lcqmc_pred_bert = bert_predict(bert_model, lcqmc_test_dl)\n",
    "paws_pred_bert = bert_predict(bert_model, paws_test_dl)\n",
    "\n",
    "pd.DataFrame(corpus_pred_bert, columns=['prediction']).to_csv('submit/bert/bq_corpus.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(lcqmc_pred_bert, columns=['prediction']).to_csv('submit/bert/lcqmc.tsv', sep='\\t', index_label='index')\n",
    "pd.DataFrame(paws_pred_bert, columns=['prediction']).to_csv('submit/bert/paws-x.tsv', sep='\\t', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "中文文本相似度.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
